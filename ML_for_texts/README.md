# МО для текстов: определение токсичности комментариев

[html](https://github.com/TomashA1980/Portfolio_All_Practicum_Projects/blob/main/ML_for_texts/ML_for_texts.html)    [ipynb](https://github.com/TomashA1980/Portfolio_All_Practicum_Projects/blob/main/ML_for_texts/ML_for_texts.ipynb)

## Описание проекта

Интернет-магазин запускает новый сервис. Клиенты предлагают свои правки и комментируют изменения других. 
Требуется инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.


## Навыки и инструменты

- **python**
- **pandas**
- **nltk**
- **tf-idf**
- sklearn: **LogisticRegression**,
- **LGBMClassifier**



## Вывод
Мы, конечно, берегли аппаратную часть и свои нервы, поэтому убрали особо длинные словоизлияния, но...

Поигрались с **BERT**:

Колаб бесплатно работать не хочет и через 5 часов работы останавливает работу
Локально получилось получить только 8000 эмбедингов, что хватило только на 0,23 и никакая балансировка не помоглала.

Откатились к более базовому варианту с TF-IDF, но тоже на сахар:

на 20% данных 0,71
только обработав все данные получили результат по метрике F1, который соответствовал поставленной задаче.

Что интересно, в этой задаче достаточно быстрой Логистической регрессии, если хорошо подготовить и сбалансировать данных. Но существуют мощьные модели, которые надежно дают нужный результат.
